<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>ECE 4960: Fast Robots</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">ECE 4960</a>
                <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars ml-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#portfolio">Labs</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#team">Team</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#services">About</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container">
                <div class="masthead-subheading">Kathleen Wang</div>
                <div class="masthead-heading text-uppercase">ECE 4960: Fast Robots</div>
                <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#services">Tell Me More</a>
            </div>
        </header>
        <!-- Portfolio Grid-->
        <section class="page-section bg-light" id="portfolio">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Labs</h2>
                </div>
                <div class="row">
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal1">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://cdn.sparkfun.com/r/500-500/assets/parts/1/4/0/1/8/15443-SparkFun_RedBoard_Artemis_Nano-05.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 1</div>
                                <div class="portfolio-caption-subheading text-muted">Artemis Setup</div>

                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://cdn0.iconfinder.com/data/icons/social-media-2219/50/72-512.png" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 2</div>
                                <div class="portfolio-caption-subheading text-muted">Bluetooth Communication</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal3">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://i.ibb.co/RvTNDcd/Screen-Shot-2020-09-03-at-9-42-31-PM.png" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 3</div>
                                <div class="portfolio-caption-subheading text-muted">Characterize Your Car</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal4">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://previews.123rf.com/images/larryrains/larryrains1901/larryrains190100022/118556682-gears-a-vector-cartoon-illustration-of-a-few-spinning-gears-.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 4</div>
                                <div class="portfolio-caption-subheading text-muted">Motor driver & open loop control</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal5">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://www.biblicalministries.org/wp-content/uploads/2019/01/9-3-0-1776930_obstacles_web.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 5</div>
                                <div class="portfolio-caption-subheading text-muted">Prox, TOF, Obstacle avoidance</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal6">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://cdn.sparkfun.com//assets/parts/1/3/8/6/0/15335-SparkFun_9DoF_IMU_Breakout_-_ICM-20948__Qwiic_-01b.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 6</div>
                                <div class="portfolio-caption-subheading text-muted">IMU</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal7">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://www.researchgate.net/profile/Yacine_Ahmine/publication/293488676/figure/fig1/AS:326982060527616@1454970006384/Representation-of-the-differential-drive-mobile-robot.png" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 7</div>
                                <div class="portfolio-caption-subheading text-muted">Odometry</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal8">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://previews.123rf.com/images/freaktor/freaktor1908/freaktor190800342/132521020-gps-icon-vector-design-map-pointer-icon-pin-location-symbol-flat-design-style-navigation-icons-for-w.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 8</div>
                                <div class="portfolio-caption-subheading text-muted">Mapping</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal9">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://previews.123rf.com/images/freaktor/freaktor1908/freaktor190800342/132521020-gps-icon-vector-design-map-pointer-icon-pin-location-symbol-flat-design-style-navigation-icons-for-w.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 9</div>
                                <div class="portfolio-caption-subheading text-muted">Localization</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal10">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://www.yalasarat.com/wp-content/uploads/2019/12/Clipart-Map-Path-Path-Png-720x664.jpg" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 10</div>
                                <div class="portfolio-caption-subheading text-muted">Planning</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal11">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://cdn2.iconfinder.com/data/icons/arrows-1-3/128/Looped-Loop-Refresh-Repeat-Arrow-Feedback-512.png" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 11</div>
                                <div class="portfolio-caption-subheading text-muted">PID Control</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-4 col-sm-6 mb-4">
                        <div class="portfolio-item">
                            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal12">
                                <div class="portfolio-hover">
                                    <div class="portfolio-hover-content"><i class="fas fa-plus fa-3x"></i></div>
                                </div>
                                <img class="img-fluid" src="https://www.researchgate.net/profile/Jian_Huang14/publication/285576864/figure/fig6/AS:328305132752907@1455285451614/Mobile-wheeled-inverted-pendulum-MWIP-system-model.png" alt="" />
                            </a>
                            <div class="portfolio-caption">
                                <div class="portfolio-caption-heading">Lab 12</div>
                                <div class="portfolio-caption-subheading text-muted">Inverted pendulum</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- Team-->
        <section class="page-section bg-light" id="team">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">The Team</h2>
                </div>
                <div class="row">
                    <div class="col-lg-6">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="https://media-exp1.licdn.com/dms/image/C4D03AQHAM8usMoXLTQ/profile-displayphoto-shrink_200_200/0?e=1604534400&v=beta&t=QgrcMjwAYbI3YZ0HGfo3G08yeZ0q_yvwKn_Ob0QyhzU" alt="" />
                            <h4>Kathleen Wang</h4>
                            <p class="text-muted">Hi! I'm a junior in ECE and I'm not quite sure what area I'm going to pursue but I have interests in power, optics, and also robotics. I rock climb in my free time (or I did before COVID) and like hiking as well.</p>
                        </div>
                    </div>
                    <div class="col-lg-6">
                        <div class="team-member">
                            <img class="mx-auto rounded-circle" src="https://i.ibb.co/RvTNDcd/Screen-Shot-2020-09-03-at-9-42-31-PM.png" alt="" />
                            <h4>Robot</h4>
                            <p class="text-muted">Beep Boop</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- Services-->
        <section class="page-section" id="services">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">About</h2>
                </div>
                <div class="row text-center">
                    <div class="col-md-4">
                        <span class="fa-stack fa-4x">
                            <i class="fas fa-circle fa-stack-2x text-primary"></i>
                            <i class="fas fa-compass fa-stack-1x fa-inverse"></i>
                        </span>
                        <h4 class="my-3">Location</h4>
                        <p class="text-muted">Collegeville, PA (Working from home though the CEI Lab is located at Cornell University, Ithaca NY)</p>
                    </div>
                    <div class="col-md-4">
                        <span class="fa-stack fa-4x">
                            <i class="fas fa-circle fa-stack-2x text-primary"></i>
                            <i class="fas fa-asterisk fa-stack-1x fa-inverse"></i>
                        </span>
                        <h4 class="my-3">Focus of the Class</h4>
                        <p class="text-muted">Systems level design and implementing dynamic autonomous robots</p>
                    </div>
                    <div class="col-md-4">
                        <span class="fa-stack fa-4x">
                            <i class="fas fa-circle fa-stack-2x text-primary"></i>
                            <i class="fas fa-bullseye fa-stack-1x fa-inverse"></i>
                        </span>
                        <h4 class="my-3">Goals</h4>
                        <p class="text-muted">Designing a fast autonomous car and exploring dynamic behaviors, acting forces, sensors, and reactive control on an embedded processor</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Footer-->
        <footer class="footer py-4">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-6 text-lg-left">ECE 4960: Fast Robots</div>
                    <div class="col-lg-6 text-lg-right">
                        <a class="mr-3" href="#!">Privacy Policy</a>
                        <a href="#!">Terms of Use</a>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Portfolio Modals-->
        <!-- Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 1</h2>
                                    <p class="item-intro text-muted">Artemis Setup</p>
                                    <p> The purpose of this lab was to get set up and familiar with the Arduino IDE 
                                        and the Artemis board. After this lab, I was able to program your board, 
                                        blink the LED, read/write serial messages over USB, 
                                        display the output from the onboard temperature sensor, 
                                        measure the loudest frequency recorded by the Pulse Density Microphone, 
                                        and run the board using a battery instead of my computer.
                                    <iframe src="https://www.youtube.com/embed/8LKjbkkgvhA"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe> 
                                    <p>I was able to successfully connect to the Artemis Nano module and run the Blink Example. </p>
                                    <iframe src="https://www.youtube.com/embed/vm0y8BuSDVY"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p>I ran the Example2_Serial script and confirmed that the serial port was working.</p>
                                    <iframe src="https://www.youtube.com/embed/IJWTqguVpnw"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p>I also ran the analogRead example and could read out the voltage and temperature of the module.</p>
                                    <iframe src="https://www.youtube.com/embed/IDdPbYTTa5o"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe> 
                                    <p>The Example1_MicrophoneOutput script allowed me to read the loudest frequency on the serial port. I demonstrated by snapping my fingers (I sadly have the inability to whistle so I did that instead).</p>
                                    <iframe src="https://www.youtube.com/embed/yrq7vnrmgFE"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe>
                                    <p>Lastly, I modified the microphone script in order to cause the LED to turn on when it recognized a loudest frequency value of above 4000.</p>
                                    <p></p>
                                    <ul class="list-inline">
                                        <li>Date: September 10, 2020</li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 2-->
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-left">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 2</h2>
                                    <p class="item-intro text-muted">Bluetooth Communication</p>
                                    <img class="img-fluid" src="https://cdn0.iconfinder.com/data/icons/social-media-2219/50/72-512.png" alt="" />
                                    <p></p>
                                    <p><b>Materials/Code Needed</b></p>
                                    <p>
                                        1 x SparkFun RedBoard Artemis Nano
                                        <br> 1 x USB A-C cable
                                        <br> 1 x Bluetooth adapter
                                        <br> Distribution code
                                    </p>
                                    <p>This lab involved testing the low-latency, moderate-throughput wireless communication between the Artemis board and a computer via Bluetooth LE.
                                        The main files to be modified for this lab were <code>ECE_4960_Robot.ino</code>, which was the Arduino sketch to be uploaded, and main.py, which was the Python Bluetooth example.  </p>
                                    <p>I first plugged in my Artemis board with my USB-C cable and then set up the USB passthrough to my Ubuntu VM through the VirtualBox Extension Pack and also installed Bleak, a GATT client software capable of connceting to BLE devices.
                                        After setting up the USB passthrough, I was able to download the distribution code and run the <code>ECE_4960_Robot.ino</code> file for with the Arduino IDE and then the <code>main.py</code> to try to discover my robot, 
                                        caching the address "66:77:88:23:BB:EF" to <code>Settings["cached"]</code> in <code>settings.py</code>. I noticed sometimes
                                        the Bluetooth will fail to communicate, and in that case, I just turn off and turn back on Bluetooth under "Settings" in my VM, which 
                                        usually resolves the issue.</p>
                                    <p> Here's a screenshot of the Serial Monitor of the Arduino side:</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/Connect_to_Artemis.PNG" alt="" />
                                    <p>In the distribution code, <code>command.h</code> includes a 99-byte structure (cmd_t) with the first byte as the command type, the second as a length, and the rest as data.</p>
                                    <p>Initially, to check my connection with the robot, I had to run <code> await theRobot.ping()</code> in the asynchronous function <code>myRobotTasks()</code> </p>
                                    <p>I was able to successfully discover my robot after configuring the Bluetooth and the received output was a bunch of print-out statements confirming the ping (and pong) as well as the round trip latency. 
                                        On average, the round-trip latency looked to be around 0.114 seconds. </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/Pong times.jpg" alt="" />
                                    <p>Also, as shown in the screenshot and by what I observed by graphing the latencies for 60 pings, 
                                        this seemed to be fairly consistent throughout all the pings, with most falling between 0.11 and 0.12 seconds. </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/Histogram_pongtimes.PNG" alt="" />
                                    <p>This is definitely slower than our baud rate of 115200 symbols/sec. </p>
                                    <p></p>
                                    <p><b>Requesting a float</b></p>
                                    <p>To request a float, on the Python script side, I first commented out <code>await theRobot.ping()</code> and instead used <code>await theRobot.sendCommand(Commands.REQ_FlOAT)</code>.
                                    In the Arduino sketch, I wrote the code shown below that the script jumps to when it receives the REQ_FLOAT case. 
                                    There's a data structure called <code>res_cmd</code> with three fields: 
                                    <code>data</code> (the data(float) to send), 
                                    <code>command_type</code> (in this case, it's <code>GIVE_FLOAT</code> which the Python side will recognize and then print the float),
                                     and <code>length</code> (which is the length of the data).</p>
                                    <p>I put in the values for the command type and length as described, and then used 
                                    <code>memcpy(dest adr, src adr, size of data)</code>, a function suggested on Campuswire, to put in a float that starts at <code>res_cmd->data</code>
                                    I was then able to use <code>amdtpsSendData((uint8_t*)res_cmd, 6)</code> to send the float, using 6 for the second field because
                                    it's the size of a float (4 bytes), the length (1 byte), and the command type (1 byte).
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/case_req_float.PNG" alt="" />
                                    <p>Through the simpleHandler on the Python side, I was able to unpack the float I sent. 
                                        The <code>main.py</code> program recognized the <code>command_type</code> to be <code>GIVE_FLOAT</code> I sent
                                        from the Arduino side, and unpacked the bytes as a little-endian float, shown below
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/pi.PNG" alt="" />
                                    The value displayed is not quite the value I sent (which was 3.1415), so I guess the accuracy only goes up to whatever
                                    digit you sent. 
                                    <p></p>
                                    <p><b>Testing the Data Rate</b></p>
                                    <p>Our last subject to cover is finding out what the round-trip latency was by streaming bytes from the Artemis to my computer. 
                                    In the main Python script, I found the code in my function <code>myRobotTasks()</code> with 
                                    <code>await theRobot.testByteStream(25)</code>. Then in the Arduino sketch, I added in code for the case <code>if (bytestream_active)</code>.
                                    I sent an example of a 32 bit integer and a 64 bit integer, copying the data for the 64 bit integer to reside in the 
                                    address right after the 32 bit integer using <code>memcpy()</code>. In my case, since I wanted to 
                                    find the average time between packets sent, I had my 32 bit integer be the number of packets 
                                    the Arduino was sending and the 64 bit integer be the time lapsed between transmissions of packets, as shown below.
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/arduino_bytestream.PNG" alt="" />
                                    On the Python side, I first unpacked the byte array into two byte arrays using <code>first, second = unpack("4s8s",data)</code>, and then unpacked those again into an integer and a long
                                    respectively. I then printed out the number of packets received, the time in microseconds between packets, 
                                    the time in seconds between packets, and the number of packets sent on the Arduino side. 
                                    This is shown in the figure. 
                                    <img class="img-fluid d-block mx-auto" src="assets/img/data_bytestream_latency.PNG" alt="" />
                                    <p>(# Arduino packets, time in us, time in s, # Python packets)</p>
                                    <p>
                                    I will note that one bug I ran into that confused me for a little while was that the amount of packets I counted
                                    that were being sent from the Arduino side were significantly less than the packets being received over 
                                    Bluetooth. Obviously, this was very very wrong because packets don't just start multiplying and increasing in quantity
                                    from the receiving side. I realized this was an issue with the threading in the Python script and how all of them
                                    didn't completely end since I was rerunning the program back-to-back too quickly, meaning apparently all the threads didn't close,
                                    and leading to me having about 8 <code>main.py</code> functions running at the same time (which is a bit of a yikes).
                                    Luckily, this was resolved and can apparently be mitigated by just waiting a bit after ending the program instead of running it immediately after.
                                    </p>
                                    Here is a histogram of the time between packets in milliseconds when sending a 32 bit and 64 bit integer (14 bytes).
                                     The average time is 10.77 ms with a SD of 0.306 ms.
                                    <img class="img-fluid d-block mx-auto" src="assets/img/histogram_packet_times.PNG" alt="" />
                                    <p>The average time was also about the same for a different amount of bytes (50 bytes) as shown below, with an average of 10.83 ms. 
                                        I attempted this by doing 4 32 bit integers and 4 64 bit integers. 
                                        I think the reason they're about the same is because you're still sending 99 bytes. 
                                         </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/histogram_more_packets_time.PNG" alt="" />
                                    <p> The big difference I think comes with the packet loss percentage. When sending 14 bytes,
                                    after 2000 packets sent, there were about 1585 received. This is a loss percentage of 20.75%. However, 
                                    when I attempted to send 50 bytes, I got a loss percentage of 58.9% which is much higher than I expected.
                                    Therefore, if you wanted to transfer a large set of data this way, you would have to send it in small packets (as opposed to trying to stuff
                                    the 99 byte buffer with as much data as possible). This might take awhile (a second or two), but it would give you more reliable data. 
                                    </p>
                                    <ul class="list-inline">
                                        <li>Date: September 19, 2020</li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 3-->
        <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 3</h2>
                                    <p class="item-intro text-muted">Characterizing the car</p>
                                    
                                    <p></p>
                                    <p><b>Characterizing The Car:</b></p>
                                    <p>The goal of this part of the lab was to document the car in any way that I thought 
                                        might be useful later on. Here are some useful measurements/observations:
                                    </p>
                                    <p></p>
                                    <p><b>Dimensions and Basic Stats:</b></p>
                                    <div class="parent">
                                        <ul>
                                            <li>Weight of the car:</li>
                                            <ul>       
                                                <li>Weight of car with yellow battery: <b>541 g (1.19 lb)</b></li>  
                                                <li>Weight of car with green battery: <b>523 g (1.15 lb)</b></li>                                      
                                            </ul>
                                            <li>Width between axes of left and right wheel: <b>10.35 cm (4.075 in)</b> </li> 
                                            <li>Distance between front axis and back axis (wheelbase): <b>7.9 cm (3.11 in)</b></li>  
                                            <li>Dimensions of black base of the car: <b>12 cm x 6.5 cm</b></li>
                                            <img class="img-fluid d-block mx-auto" src="assets/img/lab3/IMG_1099.png" width="500" height = auto alt="" />
                                            <li>Diameter of wheels: <b>77.5 mm</b> (useful for future labs involving distance traveled)</li>
                                            <li>Width of wheels: 3.5 cm</li>
                                            <img class="img-fluid d-block mx-auto" src="assets/img/lab3/IMG_1100.png" width="500" height = auto alt="" />
                                            <li>Time to charge battery: around 4-5 hours (wasn't watching it near the end but that seems like a good estimate)</li>
                                            <li>Battery life of car: 32 minutes not running at full speed the whole time (probably around 20 minutes)</li>
                                            <li>Number of "clicks" when rotating a wheel slowly: 120 (shown in video below)                                           <video controls="controls" width="800" height="600" 
                                                name="Video Name" src="assets/img/lab3/IMG_1105.mov"></video></li>
 
                                        </ul>     
                                    </div>
                                    <p></p>
                                    <p> <b>Testing the Car's Capabilities:</b></p>
                                    <div class="parent">
                                        <ul>
                                            <li>Max Angle of Incline without slipping (not in motion): 21 degrees:  </li> 
                                            <img class="img-fluid d-block mx-auto" src="assets/img/lab3/Incline.JPG" width="400" height = auto alt="" />
                                            <li>I tested the robot on multiple surfaces:
                                                <p></p>
                                                <ul>
                                                    <li>Hardwood floor: runs very smoothly (ideal conditions)</li>
                                                    <li>Grass: runs surprisngly well</li>
                                                    <li>Carpet: basically the same as grass (a little bit better)</li>
                                                    <li>Driveway: yep checks out</li>
                                                </ul> 
                                                
                                            </li>
                                            <li>The robot can reliably turn around its own axis most of the time, at both fast and slow speeds.
                                                With the robot spinning around its own axis at full speed, 
                                                I was able to record how many rotations the robot could complete in a certain amount of time. After 
                                                averaging three trials, I got a max rotational speed of 1.73 rotations/sec, or <b>10.87 rad/sec</b>. This happened when 
                                                the battery was at approximately full capacity. 
                                            </li>
                                            <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab3/spin.MOV"></video>
                                            <li>Distance needed to stop after starting from full speed (averaged from 5 trials): <b>4.7 feet</b></li>
                                            <li>Braking distance in slow mode: <b>5.5 inches</b></li>
                                            <li>Acceleration:
                                                <ul>
                                                    <li>I attempted to measure how quickly the car could change speeds by placing tape indicators every 10 inches on the floor and seeing how much the 
                                                         velocity of the car increased from rest. The car is capable of accelerating at a quick pace, and this acceleration seems to remain
                                                        relatively similar regardless of the battery charge left on the robot. Note: in the following trials described,
                                                         the battery was at around 75% of its full capacity.</li> 
                                                    <li>After four trials and analyzing each video in slow motion, I roughly estimated that the
                                                         robot is capable of reaching 3.8 ft/s after just 0.3 seconds and should reach its max speed within 0.7 seconds after starting from rest. 
                                                         I wasn't able to get a solid value for the acceleration without any sensors currently on the car.
                                                     </li>
                                                    <video controls="controls" width="800" height="600" 
                                                     name="Video Name" src="assets/img/lab3/Acceleration.mp4"></video>
                                                </ul>
                                            
                                            <li> I was also able to determine the robot is capable of a decently wide set of velocities, measuring the speed using
                                                the method below. I had the robot start earlier than my 10 inch distance markings (so I would start
                                                measuring the velocity after it had finished accelerating). I then watched the video in slow motion to determine the velocity.
                                            <li>The max and minimum speeds the robot can achieve seem to be highly dependent on battery
                                                    life. At a low battery level, it is capable of very slow speeds (especially in slow mode). However, at almost full battery
                                                    capacity and based on the data, it appears the robot can reach up to <b>8.33 ft/sec (2.5 m/s)</b> </li> 
                                            </li>
                                            <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab3/IMG_1089 (3).mov"></video>
                                        </ul>  
                                    </div> 
                                    <p><b>Manual Control:</b></p>
                                    <div class="parent">
                                        <ul>
                                            <li>There seem to be three different speed options (faster, intermediate, slower). The middle and
                                                faster option are hard to control, especially the faster option. With the max possible speed, I was basically
                                                constantly flipping the robot when I was driving it around. </li>
                                                <li>The robot is very prone to flipping when running 
                                                at full speed due to its center of mass being a bit high. I think when we take off the top of the robot, it'll
                                                be able to have more stability due to a lower center of mass.</li>
                                           
                                            <li>Starting from about a 5 meter distance at full speed, I could get about 4 inches from the wall without crashing,
                                                though this involved practicing multiple times to make sure I knew when to slow down quickly enough. Based on the braking distance
                                                I measured for when the robot needed to go from full speed to a complete stop, I was able to accurately stop the car by 
                                                braking about 5 feet from the wall, as mentioned previously.
                                            </li>
                                            
                                        </ul>
                                    </div>
                                    <p></p>
                                    <p><b>Tricks:</b></p>
                                    <div class="parent">
                                        <ul>
                                            </li> I couldn't get the robot to balance on one set of wheels reliably. I wasn't able to 
                                            get it into that position at a lower speed, and the quicker speeds were not controllable to 
                                            the extent where I could come close to getting the robot to balance itself. Occasionally, if I got the
                                            robot to flip halfway, I could get it to briefly balance on one set of wheels, but it seems to 
                                            be a trick that requires more fine tuned feedback control. </li>
                                            <li>I was easily able to get my car to flip (by going forwards and then quickly flipping the joystick backwards)</li>
                                            <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab3/IMG_1062 (3).MOV"></video>
                                            <li>I could get the robot to perform some decently fine-tuned actions. For example, I was able to do parallel parking 
                                                with my robot.
                                            </li>
                                            <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab3/Parallel Parking.mp4"></video>
                                            <p>(Yikes, my robot is better at parallel parking than me)</p>
                                            <p></p>
                                            <li>Additionally, my robot generates enough force to break in to a door.</li>

                                            <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab3/Breaking and Entering.mp4"></video>
                                            <p>(Breaking and Entering)</p>
                                        </ul>
                                    </div>
                                            

                                    <p><b>Running the Virtual Robot</b></p>
                                    <p>I installed the software dependencies and setup the base code in my VM.
                                        I then was able to run <code>lab3-manager</code>, pressing <code>a</code> and <code>s</code>
                                        to start the simulator, allowing me to run tests on my robot. 
                                        Additionally, I ran <code>robot-keyboard-teleop</code> to control the virtual robot through 
                                        keyboard commands. 
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab3/ROS_screen.PNG" alt="" />
                                    <p>The robot can go to very low linear and angular speeds (to where it's basically not moving), 
                                        as well as very high linear and angular speeds (as shown below). This is due to the robot being
                                        a simulation, meaning it can change it's angular and linear speed/direction practically instantaneous, currently 
                                        without the factors of friction, skidding, etc. 
                                    </p>
                                    <iframe src="https://www.youtube.com/embed/k_qDW1eqgDI"
                                    width="560" height="315" frameborder="0" allowfullscreen></iframe> 
                                    <p>Robot moving in the simulation (Gotta go fast) </P>
                                    <p></p>
                                    <p>From my few tests on the virtual robot, I could see that when the robot bumps into an obstacle,
                                            a warning sign will pop up and the simulation will pause, 
                                            meaning you then have to manually drag your robot back to 
                                            a non-obstacle occupied place. </p>
                                    <ul class="list-inline">
                                        <li>Date: September 23, 2020</li>
                                    </ul>
                                    <p></p>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 4-->
        <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">                                                                                   
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 4</h2>
                                    <p class="item-intro text-muted">Motor driver & open loop control</p>
                                    <p>The purpose of the lab was to change from manual to open loop control of the car. At the end of the lab,
                                        my car was able to execute a pre-programmed series of moves using the Artemis board and the motor driver over I2C.
                                    </p>
                                    <p>Parts Required:</p>
                                    <div class="parent">
                                            <ul>
                                                <li>1 x SparkFun RedBoard Artemis Nano</li>
                                                <li>1 x USB A-to-C cable</li>
                                                <li>1 x Li-Ion 3.7V 400 or 500mAh battery</li>
                                                <li>1 x Sparkfun Qwiic motor driver</li>
                                                <li>1 x R/C stunt car and NiCad battery</li>
                                                <li>1 x Qwiic connector</li>
                                                <li>1 x Small screwdriver (Phillips or flathead)</li>
                                                <li>1 x Wirecutter (you can also make do with a scissor)</li>          
                                            </ul>
                                    </div>
                                    <p><b><font size = "+2">Lab 4a: </font></b></p>
                                    <p>I first hooked up the Artemis and the motor driver using a Qwiic connector. I then ran Example_wire
                                        and found the I2C address to be 0x5D (93).
                                    </p>
                                    <p>I then took the car apart, unscrewing and removing the shell/bumpers from the car. I also removed
                                        the battery and took out the control PCB, cutting its power lines. I hooked up the power wires to the SCMD instead
                                        noting where the VIN on the SCMD marks the location of the positive terminal.
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab4/noPCB.JPG" alt="" />
                                    <p>After that, I cut the connector headers from the motor wires and instead hooked them up to the terminals on the board instead. I mounted the 
                                        SCMD in the place of the original control PCB and then used the Qwiic connector to hook 
                                        up the Artemis board with the motor driver. Note: since the Qwiic connector was too big to route through the hole in the chassis,
                                        I just drilled a bigger hole there so I could feed the wires through. 
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab4/motordriver.JPG" alt="" />
                                    <p>Additionally, I added a red jumper between the PSWC pins on the Artemis board so 
                                        I could easily switch on and off the board (meaning I didn't have to yank out the battery connector everytime)
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab4/IMG_1123.JPG" alt="" />
                                    <p>Using the Arduino library manager, I installed the SCMD (Serial Controlled Motor Driver) library. I was then able to make the robot
                                        follow a straight line, noticing that the right motor is stronger than the other. Therefore, for the left motor to go forwards 
                                        (motorNum = 0 and direction = 1), I had to
                                        compensate for the imbalance with <code>myMotorDriver.setDrive(0, 1, 118)</code> to drive the left motor. For the right motor to go forwards
                                         (motorNum = 1, direction = 1),
                                        I did <code>myMotorDriver.setDrive(1, 1, 100)</code>. 
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab4/Capture.PNG" alt="" />
                                    <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab4/IMG_1117.MOV"></video>
                                    <p> I then tested the lower limit for which each motor still turns.
                                        For the left motor, this seemed to be around <code>myMotorDriver.setDrive(0, 1, 68)</code>, while for the right motor
                                        it seemed to be around <code>myMotorDriver.setDrive(1, 1, 50)</code> </p>
                                    <p>Technically, the motors are 
                                        able to start at lower values, but I have to give the wheels a little help (a nudge to start) so I only counted
                                        the threshold where the wheels could fully turn without any assistance at the beginning from me. Additionally, I only
                                        counted the threshold where the car could actually move forwards. The wheels could spin at a lower threshold with the car on its back
                                        but I thought this wouldn't be as important since the robot couldn't actually go forwards with the inhibitions of friction and the weight 
                                        of the car.
                                    </p>
                                    <p>Lastly, I just used open loop control of the robot to drive it around and make it spin around its own axis. </p>
                                    <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab4/IMG_1119.mov"></video>
                                    <p></p>



                                    <p><b><font size = "+2">Lab 4b: Open Loop Control</font></b></p>
                                    <p><b>Setting up the Base Code and Starting the Simulator</b> </p>
                                    <p>I setup the base code by extracting the lab 4 base code in VM and typing <code>./setup.sh</code> in my terminal, 
                                       successfully compiling the lab</p>
                                    <p>To start the lab4-manager, I opened a terminal window and typed in <code>lab4-manager</code>
                                        I then launched the simulator by pressing "a" and then "s" on my keyboard.</p>
                                    </p>
                                    <p><b>Jupyter Lab Code</b> </p>
                                    <p>We were introduced to Jupyter Lab to write our Python code. To start a Jupyter server, I did the following:
                                    </p>
                                    <div class="parent">
                                        <ul>
                                            <li>Opened a terminal and cd into <code>/home/artemis/catkin_ws/src/lab4/scripts</code>.</li>
                                            <li>Started a jupyter server using <code>jupyter lab</code></li>
                                            <li>Opened "lab4.ipynb"</li>
                                        </ul>
                                    </div>
                                    <p>I was then able to work with the Robot Class which provides a control interface for the robot in
                                        the simulator and performs the following operations: getting the robot odometry pose, moving the robot, and getting 
                                        range finder data. </p>
                                    <p>In order to have my robot move in a rectangular loop, I first imported the necessary modules for 
                                        my Python script and then instantiated/initialized an object of class Robot. I then set the linear velocity to a value and the angular velocity 
                                        to 0, let this run for a length of time, and then set the linear velocity to 0 and the angular velocity to a value, letting this run for a length of time. 
                                        By tuning my values, I could make the angles 90 degrees and modify the size of my rectangle by changing the amount of time I let the robot run with a 
                                        non-zero linear velocity. </p>
                                    <p>To set the lengths of time, I used the time.sleep() function and to make 90 degree turns, I had the angular velocity be set to 2 for 1 second. </p>
                                    <p>My code and demonstration are shown below:</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab4/Jupyter_code_Lab4.PNG" alt="" />
                                    
                                    <video controls="controls" width="800" height="600" 
                                            name="Video Name" src="assets/img/lab4/IMG_1092.MOV"></video>
                                    </p>
                                    <ul class="list-inline">
                                        <li>Date: September 29, 2020</li>
                                    </ul>
                                    <p></p>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 5-->
        <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <!--<div class="row justify-content-center">-->
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 5</h2>
                                    <p class="item-intro text-muted">Prox, TOF, Obstacle avoidance</p>
                                    <div align = "left">
                                    <p>The purpose of the lab was to enable the robot to perform obstacle avoidance by putting distance sensors
                                        on the car, getting them working, and then attempting fast motion around the room without crashing into obstacles. 
                                        </p>
                                        <p>Parts Required:</p>
                                        <div class="parent">
                                                <ul>
                                                    <li>1 x SparkFun RedBoard Artemis Nano</li>
                                                    <li>1 x USB A-to-C cable</li>
                                                    <li>1 x 4m ToF sensor</li>
                                                    <li>1 x 20cm proximity sensor</li>
                                                    <li>1 x Li-Ion 3.7V 400 or 500mAh battery</li>
                                                    <li>1 x Sparkfun Qwiic motor driver</li>
                                                    <li>1 x R/C stunt car and NiCad battery</li>
                                                    <li>1 x Qwiic connector</li>
                                                    <li>1 x Gray target</li>
                                                    <li>1 x Ruler or graph paper</li>  
                                                    <li>1 x Double sided tape</li>        
                                                    <li>1 x Small screwdriver</li>
                                                    <li>1 x Wirecutter</li>
                                                </ul>
                                        </div>
                                    <p><b><font size = "+2"> Lab 5a: Obstacle Avoidance</font></b></p> 
                                    <p><b>Prelab:</b></p>    
                                    <p>I read over the datasheet and manual for the proximity board and found the device address to be 0x60.
                                        I also read over the documentation for the ToF breakout baord, which has an I2C address of 0x52.
                                    </p>
                                    <!--Given their range and angular sensitivity, 
                                        think about where you will place them on your robot to best detect obstacles. 
                                        Discuss scenarios where your robot will miss obstacles.--> 
                                    <p>
                                        The Proximity Sensor Breakout apparently has no dead zone and can read from 0 cm (the face of the sensor) to about 20 cm away. However,
                                        as shown by the Gaussian-shaped angular sensitivity curve in the datasheet, it doesn't have a wide angular range. It's also not very
                                        accurate for detecting the exact quantitative distance readings but it is good at seeing if objects appear in front of it. I think ideally we would
                                        walk to put it on the front of the car to ensure we are not bumping into objects in front of the robot, but they'll be scenarios where the robot will bump into
                                        things on the side since it basically lacks peripheral vision or sensors. Additionally, just having that one sensor in the front would obviously mean the robot would
                                        not be able to see behind itself and would therefore run into any items behind it (and by that logic, also objects above it and any bumps
                                        in the ground as well)). Also, since the range is only 20 mm, there might be situations where the robot is close to an object but does not detect
                                        it due to inaccuracies in the sensor or being just over 20 mm away, meaning the robot would not be able to react/stop in time. 
                                    </p>
                                    <p>The ToF breakout board has a FoV from 15-27 degrees so it's basically just for looking straight forwards as well. It has a max distance of either
                                        136, 290, or 360 cm in the dark but this distance is less in ambient light (where it's more sensitive)</p>.
                                        <p>It will have more difficulty in
                                                terms of sensitivity to objects in bright light, and it will also have the same narrow FoV problems as the proximity sensor. However, it is much better at
                                                quantitative measurement as opposed to the proximity sensor, and is less sensitive to color and texture. Putting it in the front of the car is the best approach
                                                since the car is primarily driving forwards and then turning when it sees obstacles. The car would miss seeing obstacles similar to the proximity sensor,
                                                due to the sensor's position in the front, but it would have less problems with range since the range is 1.3m as opposed to 20 mm. </p> 
                                    <!--Many distance sensors are based on infrared trasmission. Discuss a couple, highlight the differences in their fuctionality 
                                        and the pros/cons of each. How would/will you use them on your robot?-->
                                    <p>There are a multitude of distance sensors based on IR transmission.</p>
                                    <div class= "parent">
                                        <ul>
                                            <li> Amplitude based IR sensors do not work
                                            in high ambient light and depend on a target's reflectivity. However, they are usually cheap, small, and lightweight, and can be used
                                            for sensor fusion with other more reliable sensors.
                                            <li>IR triangulation sensors are insensitive to surface color, texture, and ambient light but also do not work in 
                                                    high ambient light and have a low sample rate.</li> 
                                            <li>Lastly, there are ToF sensors (which we are using as well) which are a bit more
                                                    expensive than amplitude-based IR sensors though cheaper than triangulation sensors. 
                                                    They are insensitive to surface color, texture, and ambient light. We will be using this sensor
                                                    primarily for obstacle avoidance due to its better accuracy, range, and decreased light noise sensitivity than other sensors, with the 
                                                    proximity sensor as a backup/offering supporting data for sensor fusion. 
                                            </li>
                                        </ul>
                                    </div>
                                    
                                    <p><b>Proximity Sensor</b></p> 
                                    <p>Using the Arduino library manager, I installed the SparkFun VCNL4040 Proximity Sensor Library, hooking up the sensor to the 
                                        Artemis board using a QWIIC connector. I scanned the I2C channel to find the sensor at 0x60, which matches with the datasheet.
                                        I could then test the sensor using the Examples\SparkFun_VCNL4040_Proximity_Sensor_Library\Example4_AllReadings script.
                                    </p>
                                    <!--Test your proximity sensor using the “..\Arduino\libraries\SparkFun_VCNL4040_Proximity_Sensor_Library\examples\Example4_AllReadings”. 
                                        Map the sensor readings to the actual distance. 
                                        Try objects with different color and texture, and in different lighting conditions. 
                                        Explain if/why the sensor is sensitive to the particular parameter. 
                                        Also, note how frequent measurements are updated and how long it takes to read them.-->
                                    <p>Here is a graph of the proximity value readings vs distance for 3 different colored objects, with the tests being conducted in a well lit room.
                                        One object was a square white box, another was a pack of yellow sticky notes,
                                        and the last was my black phone. All were roughly the same size (or at least close enough), and I was able to see that the different colors did indeed impact the 
                                        proximity value. The darker the color, the lower the value. This is because the IR is likely being absorbed more by darker materials as opposed to being
                                        reflected as for light materials, meaning the reading is lower.
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/1139.JPG" alt="" />
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/colors.PNG" alt="" />
                                    <p>All of them show a drastically higher level at a closer distance as opposed to a distance further away. I think this indicates that the proximity sensor
                                        is best used for objects/obstacles that emerge very close to the robot, as it has a higher sensitivity to that range. This is further emphasized by how
                                        I graphed them using a log scale. 
                                    </p>
                                    <p>I then tested the white box in a different ambient light environment (I turned the lights off and test it in the dark). The values were very close 
                                        and basically indistinguishable from one another. I think the ambient light (visible light) doesn't interfere with the IR waves of the sensor, meaning that
                                        most normal ambient light levels shouldn't have a major impact on the proximity value. I did test the sensor once in bright sunlight and it did 
                                        not seem to work very well at all so I think a thing to note is that it has decreased performance in high ambient light. 
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/lightvdark.PNG" alt="" />
                                    <p>I also tested different types of textures. I first tried a cloth black object to compare to my solid matte black phone case, but there didn't seem to be 
                                        significant differences there. However, when I tested a black matte surface vs a black reflective surface, I saw higher values for the reflective surface because
                                    similar to the white and yellow objects previously, some of the reflective surface reflected more of the IR rays as opposed to the phone case where the light
                                    was mostly absorbed. This is a downside to the proximity sensor as it depends on the target's reflectivity. I tested with a fuzzy white object as well but there honestly didn't seem to be a huge difference between that object and the flat, smooth one. </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/mattevreflect.PNG" alt="" />
                                    <p>Lastly, I looked at the ambient light and white level data. The ambient light was lower the closer the object was to the sensor, as when it was closer it blocked
                                        more of the ambient light to hit the sensor. Additionally, the black object had the lowest ambient light and white levels due to the same reasons stated previously. 
                                    I am also assuming the shadows that resulted from when the object was very close to the proximity sensor resulted in the lower white levels for the smaller distances. 
                                    I can therefore conclude that the sensor is sensitive to ambient light, though the proximity values seem to not be affected by this ambient light. </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/amblight.PNG" alt="" />
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/whitelevel.PNG" alt="" />
                                    <p> It takes about 630 us each for each of the getWhite(), getAmbient(), and getProximity() functions, which is
                                        a fairly high rate. I found it as follows:</p>
                                        <pre><code>
                                                unsigned long time0 = micros(); 
                                                unsigned int proxValue = proximitySensor.getProximity();
                                                unsigned long measTime = micros() - time0;
                                                Serial.println(measTime);
                                        </code></pre>
                                    <p>However, I noticed that it takes about 4 seconds for the
                                        data to stabilize after a sudden change. The sensor readings can be a bit jumpy, so it's definitely better for qualitative as opposed to quantitative
                                        measurements.  
                                    </p>
                                    <p></p>



                                    
                                    <p><b>Time of Flight Sensor</b></p> 
                                    <p>Using the Arduino library manager, I installed the SparkFun VL53L1X 4m laser distance sensor library, hooking up the sensor to the 
                                        Artemis board using a QWIIC connector. I scanned the I2C channel to find the sensor at 0x60, which matches with the datasheet.
                                        I could then test the sensor using the Examples\SparkFun_VL53L1X_4m_Laser_Distance_Sensor\Example1_ReadDistance script, after first running the Calibration
                                        script with the gray target we were given with our kit, getting an average offset of 21 after running it 4 times. 
                                    </p>    
                                    <p>The timing budget (the time required by the sensor to perform a range measurement) has a min and max of 20ms and 1000ms respectively. If
                                        we wanted to collect the most amount of data and run the robot in Short Distance mode, we would want to set the timing budget to be 20 ms. 
                                        This also takes into account power consumption, and how we don't always want the sensor to constantly be collecting data). The repeatibility error
                                        is higher at lower timing budgets but the order of magnitude of the error seems low compared to how fast the robot is moving (and the large amount
                                        of distance it can cover quickly)
                                        Because of this, I've decided to set the timing budget to be 20 ms. 
                                    </p>
                                    <p>
                                        We also consider the max speed we know the robot can go at in order to determine t
                                        the measurement period (the time between when measurements start and end, when the sensor is in low power mode). The robot has a max speed of around 8 ft/s
                                        and I think the next part of the lab involves us trying to make it go as fast as possible.  
                                        I guess to ensure the robot won't collide with the wall or any objects when traveling quickly, I'm estimating that we want to 
                                        at least check the robot's position every 1 feet. Doing t = d/v, I then got a value of at least 125 ms.
                                    </p>
                                    <p>Because of this, I know that the measurement period should be around 125 - 20 = 105 ms (assuming the timing budget is 30 ms). I rounded down to get a 
                                        period of 100 ms. 
                                     </p>
                                    <p>I set these values using:</p>
                                    <div class="parent">
                                        <ul>
                                            <li><code>distanceSensor.setTimingBudgetInMs(20);</code></li>
                                            <li><code>distanceSensor.setIntermeasurementPeriod(100);</code></li>
                                        </ul>
                                    </div>  
                                    <p>To optimize the ranging performance, I decided to use the short distance mode since the room I'm running the robot in is not the
                                        largest. Additionally, the range in short distance mode is about 1.3 meters (4.25 feet) which seems to be an adequate distance to start stopping a robot
                                        going at 8 ft/s, knowing that the coasting distance (from Lab 3) was around 5 feet, and that I can cut this distance down by implementing 
                                        reverse motor controls (though not too much because then the car will flip). I set this mode using <code> distanceSensor.setDistanceModeShort();</code>.
                                    </p>
                                    <p>Sigma (the estimation of the SD of the measurement) and signal (the amplitude of the signal reflected). It appears the most common errors are
                                        a signal fail or a wrapped target fail, which seem to be due to shaking or sudden movements that the sensor sees. Since it is sensitive to these sudden
                                        movements, I can use these failure mode indications to cause the robot to stop or slow down in case it has run into rocky terrain or unexpected obstacles. 
                                    </p>
                                    <p>Lastly, I documented the ToF sensor range and accuracy. I had my test setup as shown below, running the sensor in Short Mode since that's 
                                        the mode I'm using for obstacle avoidance:</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/IMG_0563.JPG" alt="" />
                                    <p></p>
                                    <p>My data is as shown below:</p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/tof.PNG" alt="" />
                                    <p>I can conclude that the sensor has good repeatability as I ran it three times on 3 different days at roughly the same ambient light (running
                                        in the same room with the same lights on), resulting in basically identical graphs. I did 100 measurements at each distance point (which was every
                                        100 mm) and found the mean and SD at each. The ToF SD's were minimal and the ToF means were extremely close to the actual distance all the way up to around 1250 mm, 
                                        before the mean started deviating from the actual distance (increasing at a slower rate than it's original linear pace) and the SD drastically increased as well. 
                                        I can then conclude that the sensor is extremely accurate within at least a 1250 mm range. 
                                    </p>
                                    <p>I also tested in a pitch black room as opposed to my normal well lit room, and I could see that the results were a little bit closer
                                        to the actual distances for the distances further away than 1250 mm. I think this is due to the sensor being in Short Distance mode as well
                                        as ambient light starting to interfere at further distances in lighter conditions, and not so much in dark conditions where it has slighter
                                        better performance. I also tested with different colors and textures with the results being virtually identical (as opposed to the proximity sensor), 
                                        meaning this sensor is more insensitive to those aspects of objects.
                                    </p>
                                    <p>In terms of the timing measurements, which I measured using the micros() function to time certain functions:</p>
                                    <div class = "parent">
                                        <ul>
                                            <li>Just reading = 725 us</li>
                                            <li>ToF ranging (with StopRanging) = 2.87 ms</li>
                                            <li>ToF ranging (no StopRanging) = 2.42 ms</li>
                                        </ul>
                                    </div>

                                    <p></p>
                                    <p><b>Obstacle Avoidance</b></p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/IMG_1140.JPG" alt="" />
                                    <p>I first mounted the sensors, Li-Ion battery, and Artemis board firmly to the car using the double-side tape from 
                                        my kit and a bit of cardboard for the proximity and ToF sensors at the front. I daisy-chained all the sensors, the motor
                                        driver, and the Artemis board using QWIIC connectors. 
                                    </p>
                                    



                                    <p><b><font size = "+2">>Lab 5b: Obstacle Avoidance on My Virtual Robot</font></b></p> 
                                    <p>I downloaded and setup the lab5 base code in my VM like I had previously done in Lab 4. I then
                                        started the simulator from the lab5-manager using <code>lab5-manager</code>, before I changed the directory to the lab5
                                        work folder and started the Jupyter server in my VM (in the same way as Lab 4). I then opened the lab5.ipynb notebook to start the lab.
                                    </p>
                                    <p>To do object avoidance for the virtual robot, I used data from the robot's range finder. In an infinite while loop, I first started off by having the 
                                        robot turn whenever it saw a wall through an if-else statement. Basically, if the robot saw a distance less than or equal to 1,
                                        I made the robot stop and turn 
                                        around its axis at a speed of 1 for 0.25 seconds. Else I set the velocity to 1 and kept the robot going forwards for 0.1 seconds. 
                                    </p>
                                    <p>After trying this out, I saw that I could fine tune this to let the robot be able to get closer to the wall without crashing.
                                        This just required some trial and error since the robot sometimes wasn't moving at a perfect perpendicular angle to a wall, meaning that
                                        since the laser distance finder on the virtual robot seemed to primarily point straight in front of it, I couldn't make the value too small
                                        or else the robot might sometimes not see the wall and crash. I saw that a distance of
                                        0.5 was too low and led to collisions when the robot was traveling at an angle, while a value of 0.7 seemed to be about right to 
                                        take into account the nonperpendicular routes the robot might take to a wall. This also let the virtual robot get pretty close to the walls as shown. 
                                    </p>
                                    <video controls="controls" width="800" height="600" 
                                        name="Video Name" src="assets/img/lab5/My Movie.mp4"></video>
                                    <p>I played around with the durations for the times the robot went forwards or turned using the time.sleep() command
                                        which maintains the velocity designated before for the amount of seconds specified in the parameter to the sleep function. I made the robot turn about
                                        22.5 degrees each time (1/4 of 90 degrees) which ended up being a speed of 2 for a duration of 0.25 seconds. I also experimented
                                        with the linear speeds of the virtual robot in terms of trying to minimize collisions. You can make the robot go faster but then you have to 
                                        make the distance in the if-statement a little larger to compensate for this. I settled on a linear speed of 0.5, which seemed like a reasonable speed.
                                    </p>
                                    <img class="img-fluid d-block mx-auto" src="assets/img/lab5/code.PNG" alt="" />
                                    <p>There are a few situations where my obstacle avoidance code doesn't always work, such as when the robot is approaching an obstacle 
                                        sticking out at the left or right side of the robot, which it would be unable to see since it lacks peripheral vision. To get rid of this 
                                        problem entirely, you would make the robot turn in a 360 degree circle all around and check every 45 degrees or so to check
                                        that there are no obstacles. Obviously though, this can be a bit slow so the next best thing would be to increase the distance in your
                                        if statement or check more frequently (minimize the delay between each of our measurements). 
                                    </p>
                                        <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <p></p>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                            <!--</div>-->
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 6-->
        <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 6</h2>
                                    <p class="item-intro text-muted">IMU</p>
                                    <img class="img-fluid d-block mx-auto" src="https://cdn.sparkfun.com//assets/parts/1/3/8/6/0/15335-SparkFun_9DoF_IMU_Breakout_-_ICM-20948__Qwiic_-01b.jpg" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
         <!-- Modal 7-->
         <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 7</h2>
                                    <p class="item-intro text-muted">Odometry</p>
                                    <img class="img-fluid d-block mx-auto" src="https://www.researchgate.net/profile/Yacine_Ahmine/publication/293488676/figure/fig1/AS:326982060527616@1454970006384/Representation-of-the-differential-drive-mobile-robot.png" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
         <!-- Modal 8-->
         <div class="portfolio-modal modal fade" id="portfolioModal8" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 8</h2>
                                    <p class="item-intro text-muted">Mapping</p>
                                    <img class="img-fluid d-block mx-auto" src="https://previews.123rf.com/images/freaktor/freaktor1908/freaktor190800342/132521020-gps-icon-vector-design-map-pointer-icon-pin-location-symbol-flat-design-style-navigation-icons-for-w.jpg" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
         <!-- Modal 9-->
         <div class="portfolio-modal modal fade" id="portfolioModal9" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 9</h2>
                                    <p class="item-intro text-muted">Localization</p>
                                    <img class="img-fluid d-block mx-auto" src="https://previews.123rf.com/images/freaktor/freaktor1908/freaktor190800342/132521020-gps-icon-vector-design-map-pointer-icon-pin-location-symbol-flat-design-style-navigation-icons-for-w.jpg" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 10-->
        <div class="portfolio-modal modal fade" id="portfolioModal10" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 10</h2>
                                    <p class="item-intro text-muted">Planning</p>
                                    <img class="img-fluid d-block mx-auto" src="https://www.yalasarat.com/wp-content/uploads/2019/12/Clipart-Map-Path-Path-Png-720x664.jpg" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
         <!-- Modal 11-->
         <div class="portfolio-modal modal fade" id="portfolioModal11" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 11</h2>
                                    <p class="item-intro text-muted">PID Control</p>
                                    <img class="img-fluid d-block mx-auto" src="https://cdn2.iconfinder.com/data/icons/arrows-1-3/128/Looped-Loop-Refresh-Repeat-Arrow-Feedback-512.png" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
         <!-- Modal 12-->
         <div class="portfolio-modal modal fade" id="portfolioModal12" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Lab 12</h2>
                                    <p class="item-intro text-muted">Inverted pendulum</p>
                                    <img class="img-fluid d-block mx-auto" src="https://www.researchgate.net/profile/Jian_Huang14/publication/285576864/figure/fig6/AS:328305132752907@1455285451614/Mobile-wheeled-inverted-pendulum-MWIP-system-model.png" alt="" />
                                    <p>Description of lab</p>
                                    <ul class="list-inline">
                                        <li>Date: </li>
                                    </ul>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                                        <i class="fas fa-times mr-1"></i>
                                        Close Project
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Contact form JS-->
        <script src="assets/mail/jqBootstrapValidation.js"></script>
        <script src="assets/mail/contact_me.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
